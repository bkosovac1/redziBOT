{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e916781a",
   "metadata": {},
   "source": [
    "# AutoDrive - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361ff9d",
   "metadata": {},
   "source": [
    "## Install and Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b404eb9",
   "metadata": {},
   "source": [
    "**Use CUDA 12.4 with these torch versions!!!**\n",
    "\n",
    "- [Download CUDA 12.4](https://developer.nvidia.com/cuda-12-4-0-download-archive?target_os=Windows&target_arch=x86_64&target_version=11&target_type=exe_local)\n",
    "- [Download cuDNN 8.9.7](https://developer.nvidia.com/rdp/cudnn-archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44560faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install Packages ---\n",
    "#%pip install ultralytics\n",
    "#%pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "#%pip install opencv-python\n",
    "#%pip install cvzone\n",
    "#%pip install numpy\n",
    "\n",
    "# --- Import Libraries ---\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import cvzone\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439f8948",
   "metadata": {},
   "source": [
    "## Preparation and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245ae0be",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ef6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Class Names and RGB Function ---\n",
    "CLASS_NAMES = ['bicycle', 'bus', 'car', 'green-light', 'motorbike', 'pedestrian', 'red-light', 'truck', 'yellow-light']\n",
    "CLASS_NAMES_LANES = ['lane', 'road']\n",
    "\n",
    "def rgb(r, g, b):\n",
    "    return (b, g, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905738eb",
   "metadata": {},
   "source": [
    "### Configuration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e6dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration---\n",
    "\n",
    "# --- Source Settings ---\n",
    "VIDEO_SOURCE = \"data/test-videos/test-real-h.mp4\"               # Horizontal test video from iPhone camera\n",
    "#VIDEO_SOURCE = \"data/test-videos/test-real-v.mp4\"              # Vertical test video from iPhone camera\n",
    "\n",
    "#VIDEO_SOURCE = \"data/test-videos/test-cars.mp4\"                # Video for testing cars\n",
    "#VIDEO_SOURCE = \"data/test-videos/test-lights.mp4\"              # Video for testing traffic lights\n",
    "#VIDEO_SOURCE = \"data/test-videos/test-lines.mp4\"               # Video for testing lanes and roads   \n",
    "#VIDEO_SOURCE = \"data/test-videos/test-universal.mp4\"           # Video for testing everything\n",
    "\n",
    "#VIDEO_SOURCE = 0                                               # Webcam for testing real-time\n",
    "\n",
    "\n",
    "# --- Model Settings ---\n",
    "DETECTION_MODEL_PATH = \"trained-models/detection-large.pt\"\n",
    "SEGMENTATION_MODEL_PATH = \"trained-models/segmentation-large.pt\"\n",
    "\n",
    "# --- Visualization Settings ---\n",
    "COLOR_PEOPLE = rgb(130, 0, 255)\n",
    "COLOR_CARS = rgb(0, 140, 255)\n",
    "COLOR_BIG_VEHICLES = rgb(0, 255, 213)\n",
    "COLOR_SMALL_VEHICLES = rgb(7, 48, 231)\n",
    "\n",
    "TRAFFIC_LIGHT_GREEN = rgb(0, 255, 0)\n",
    "TRAFFIC_LIGHT_RED = rgb(255, 0, 0)\n",
    "TRAFFIC_LIGHT_YELLOW = rgb(255, 255, 0)\n",
    "\n",
    "COLOR_LANES = rgb(255, 0, 0) \n",
    "COLOR_ROADS = rgb(255, 255, 255) \n",
    "\n",
    "# --- Threshold Settings ---\n",
    "CONFIDENCE_THRESHOLD_DETECTION = 0.2\n",
    "CONFIDENCE_THRESHOLD_SEGMENTATION = 0.7\n",
    "OVERLAY_ALPHA = 0.25\n",
    "\n",
    "# --- Detection Settings ---\n",
    "ENABLE_PEOPLE_CARS = True\n",
    "ENABLE_TRAFFIC_LIGHTS = True\n",
    "SHOW_LIGHTS_BANNER = True\n",
    "ENABLE_LANES = True\n",
    "ENABLE_ROADS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125538db",
   "metadata": {},
   "source": [
    "### Model and Source Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c70ef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda [NVIDIA GeForce GTX 1660 SUPER]\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Models ---\n",
    "\n",
    "# --- Check Device ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device} [{torch.cuda.get_device_name(0)}]\")\n",
    "\n",
    "# --- Load Models ---\n",
    "detection_model = YOLO(DETECTION_MODEL_PATH)\n",
    "detection_model.to(device)\n",
    "\n",
    "segmentation_model = YOLO(SEGMENTATION_MODEL_PATH)\n",
    "segmentation_model.to(device)\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccfb33c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening video source: data/test-videos/test-real-h.mp4\n",
      "Video resolution: 944x544\n"
     ]
    }
   ],
   "source": [
    "# --- Video Capture ---\n",
    "print(f\"Opening video source: {\"Camera\" if VIDEO_SOURCE == 0 else VIDEO_SOURCE}\")\n",
    "cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video source\")\n",
    "    exit()\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(f\"Video resolution: {frame_width}x{frame_height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4b6d7a",
   "metadata": {},
   "source": [
    "# Run Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e5f828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video stream or error reading frame.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\n",
    "    # Read a frame from the video sourceQ\n",
    "    ret, det_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video stream or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # --- Inference ---\n",
    "    detection_results = detection_model.predict(det_frame, device=device, verbose=False, conf=CONFIDENCE_THRESHOLD_DETECTION)\n",
    "    \n",
    "    # --- Process Detections for Pedestrians, Vehicles and Traffic-lights ---\n",
    "    \n",
    "    if detection_results:\n",
    "        d = detection_results[0]\n",
    "        boxes = d.boxes.cpu().numpy()\n",
    "\n",
    "        detected_green = False\n",
    "        detected_red = False\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            conf = box.conf[0]\n",
    "            cls_id = int(box.cls[0])\n",
    "\n",
    "            if 0 <= cls_id < len(CLASS_NAMES):\n",
    "                obj_class = CLASS_NAMES[cls_id]\n",
    "                label = f\"{obj_class}: {conf:.2f}\"\n",
    "            else:\n",
    "                print(f\"Warning: Unknown class ID {cls_id} detected. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            if ENABLE_PEOPLE_CARS:\n",
    "                if obj_class == 'car':\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=COLOR_CARS, colorC=COLOR_CARS)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=COLOR_CARS, colorT=(255, 255, 255))\n",
    "                elif obj_class == 'pedestrian':\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=COLOR_PEOPLE, colorC=COLOR_PEOPLE)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=COLOR_PEOPLE, colorT=(255, 255, 255))\n",
    "                elif obj_class in ['bus', 'truck']:\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=COLOR_BIG_VEHICLES, colorC=COLOR_BIG_VEHICLES)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=COLOR_BIG_VEHICLES, colorT=(255, 255, 255))\n",
    "                elif obj_class in ['bicycle', 'motorbike']:\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=COLOR_SMALL_VEHICLES, colorC=COLOR_SMALL_VEHICLES)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=COLOR_SMALL_VEHICLES, colorT=(255, 255, 255))\n",
    "\n",
    "            if ENABLE_TRAFFIC_LIGHTS:\n",
    "                if obj_class == 'green-light':\n",
    "                    detected_green = True\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=TRAFFIC_LIGHT_GREEN, colorC=TRAFFIC_LIGHT_GREEN)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=TRAFFIC_LIGHT_GREEN, colorT=(255, 255, 255))\n",
    "                elif obj_class == 'red-light':\n",
    "                    detected_red = True\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=TRAFFIC_LIGHT_RED, colorC=TRAFFIC_LIGHT_RED)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=TRAFFIC_LIGHT_RED, colorT=(255, 255, 255))\n",
    "                elif obj_class == 'yellow-light':\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=TRAFFIC_LIGHT_YELLOW, colorC=TRAFFIC_LIGHT_YELLOW)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=TRAFFIC_LIGHT_YELLOW, colorT=(255, 255, 255))\n",
    "\n",
    "        if SHOW_LIGHTS_BANNER:\n",
    "            frame_height, frame_width, _ = det_frame.shape\n",
    "\n",
    "            if detected_green:\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(\"GREEN LIGHT\", cv2.FONT_HERSHEY_SIMPLEX, 1.2, 2)\n",
    "                padding = 10\n",
    "                bg_rect_y1 = frame_height - text_height - baseline - (2 * padding)\n",
    "                bg_rect_y2 = frame_height - padding\n",
    "                bg_rect_x1 = (frame_width - text_width) // 2 - padding\n",
    "                bg_rect_x2 = bg_rect_x1 + text_width + (2 * padding)\n",
    "\n",
    "                cv2.rectangle(det_frame, (bg_rect_x1, bg_rect_y1), (bg_rect_x2, bg_rect_y2), (0, 80, 0), cv2.FILLED)\n",
    "\n",
    "                text_x = (frame_width - text_width) // 2\n",
    "                text_y = frame_height - baseline - padding - (padding//2)\n",
    "                cv2.putText(det_frame, \"GREEN LIGHT\", (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            elif detected_red:\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(\"RED LIGHT\", cv2.FONT_HERSHEY_SIMPLEX, 1.2, 2)\n",
    "                padding = 10\n",
    "                bg_rect_y1 = frame_height - text_height - baseline - (2 * padding)\n",
    "                bg_rect_y2 = frame_height - padding\n",
    "                bg_rect_x1 = (frame_width - text_width) // 2 - padding\n",
    "                bg_rect_x2 = bg_rect_x1 + text_width + (2 * padding)\n",
    "\n",
    "                cv2.rectangle(det_frame, (bg_rect_x1, bg_rect_y1), (bg_rect_x2, bg_rect_y2), rgb(80, 0, 0), cv2.FILLED)\n",
    "\n",
    "                text_x = (frame_width - text_width) // 2\n",
    "                text_y = frame_height - baseline - padding - (padding//2)\n",
    "                cv2.putText(det_frame, \"RED LIGHT\", (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, rgb(255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # --- Display ---\n",
    "    cv2.imshow(\"AutoDrive Detection\", det_frame)\n",
    "\n",
    "    # --- Exit Condition ---\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4002217",
   "metadata": {},
   "source": [
    "# Run Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8083f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\n",
    "    # Read a frame from the video sourceQ\n",
    "    ret, seg_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video stream or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # --- Inference ---\n",
    "    segmentation_results = segmentation_model.predict(seg_frame, device=device, verbose=False, conf=CONFIDENCE_THRESHOLD_SEGMENTATION)\n",
    "    segmentation_overlay = np.zeros_like(seg_frame, dtype=np.uint8)\n",
    "    \n",
    "    # --- Process Detections for Pedestrians, Vehicles and Traffic-lights ---\n",
    "    \n",
    "    if segmentation_results:\n",
    "        s = segmentation_results[0]\n",
    "\n",
    "        if s.masks is not None:\n",
    "            masks_data = s.masks.data\n",
    "            class_ids = s.boxes.cls.cpu().numpy()\n",
    "\n",
    "            if masks_data.shape[0] > 0 and len(class_ids) == masks_data.shape[0]:\n",
    "\n",
    "                for i in range(masks_data.shape[0]):\n",
    "                    mask = masks_data[i]\n",
    "                    cls_id = int(class_ids[i])\n",
    "\n",
    "                    if 0 <= cls_id < len(CLASS_NAMES_LANES):\n",
    "                        obj_class = CLASS_NAMES_LANES[cls_id]\n",
    "                    else:\n",
    "                        print(f\"Warning: Unknown class ID {cls_id} detected. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "                    resized_mask = torch.nn.functional.interpolate(\n",
    "                        mask.unsqueeze(0).unsqueeze(0),\n",
    "                        size=(frame_height, frame_width), \n",
    "                        mode='bilinear',\n",
    "                        align_corners=False\n",
    "                    ).squeeze()\n",
    "\n",
    "                    binary_mask = (resized_mask > CONFIDENCE_THRESHOLD_SEGMENTATION).float()\n",
    "\n",
    "                    # --- Create Colored Overlay ---\n",
    "                    binary_mask_cpu = binary_mask.cpu().numpy().astype(np.uint8)\n",
    "                    bool_mask_cpu = binary_mask_cpu.astype(bool)\n",
    "\n",
    "                    if ENABLE_LANES and obj_class == 'lane':\n",
    "                        segmentation_overlay[bool_mask_cpu] = COLOR_LANES\n",
    "                    elif ENABLE_ROADS and obj_class == 'road':\n",
    "                        segmentation_overlay[bool_mask_cpu] = COLOR_ROADS\n",
    "\n",
    "                # --- Blend the Overlay with the Frame ---\n",
    "                seg_frame = cv2.addWeighted(segmentation_overlay, OVERLAY_ALPHA, seg_frame, 1 - OVERLAY_ALPHA, 0)\n",
    "\n",
    "    # --- Display ---\n",
    "    cv2.imshow(\"AutoDrive Segmentation\", seg_frame)\n",
    "\n",
    "    # --- Exit Condition ---\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d1d9a1",
   "metadata": {},
   "source": [
    "# Run Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789c3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  'source' is missing. Using 'source=C:\\Users\\eminh\\Desktop\\redziBOT\\.venv\\Lib\\site-packages\\ultralytics\\assets'.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    120\u001b[39m bool_mask_cpu = binary_mask_cpu.astype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ENABLE_LANES \u001b[38;5;129;01mand\u001b[39;00m obj_class == \u001b[33m'\u001b[39m\u001b[33mlane\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     \u001b[43msegmentation_overlay\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbool_mask_cpu\u001b[49m\u001b[43m]\u001b[49m = COLOR_LANES\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m ENABLE_ROADS \u001b[38;5;129;01mand\u001b[39;00m obj_class == \u001b[33m'\u001b[39m\u001b[33mroad\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    125\u001b[39m     segmentation_overlay[bool_mask_cpu] = COLOR_ROADS\n",
      "\u001b[31mIndexError\u001b[39m: too many indices for array: array is 0-dimensional, but 2 were indexed"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\n",
    "    # Read a frame from the video sourceQ\n",
    "    ret, det_frame = cap.read()\n",
    "    ret2, seg_frame = cap.read()\n",
    "    if not ret and not ret2:\n",
    "        print(\"End of video stream or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # --- Inference ---\n",
    "    detection_results = detection_model.predict(det_frame, device=device, verbose=False, conf=CONFIDENCE_THRESHOLD_DETECTION)\n",
    "    segmentation_results = segmentation_model.predict(seg_frame, device=device, verbose=False, conf=CONFIDENCE_THRESHOLD_SEGMENTATION)\n",
    "    segmentation_overlay = np.zeros_like(seg_frame, dtype=np.uint8)\n",
    "    \n",
    "    # --- Process Detections for Pedestrians, Vehicles and Traffic-lights ---\n",
    "    \n",
    "    if detection_results:\n",
    "        d = detection_results[0]\n",
    "        boxes = d.boxes.cpu().numpy()\n",
    "\n",
    "        detected_green = False\n",
    "        detected_red = False\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            conf = box.conf[0]\n",
    "            cls_id = int(box.cls[0])\n",
    "\n",
    "            if 0 <= cls_id < len(CLASS_NAMES):\n",
    "                obj_class = CLASS_NAMES[cls_id]\n",
    "                label = f\"{obj_class}: {conf:.2f}\"\n",
    "            else:\n",
    "                print(f\"Warning: Unknown class ID {cls_id} detected. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            if ENABLE_PEOPLE_CARS:\n",
    "                if obj_class == 'car':\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=COLOR_CARS, colorC=COLOR_CARS)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=COLOR_CARS, colorT=(255, 255, 255))\n",
    "                elif obj_class == 'pedestrian':\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=COLOR_PEOPLE, colorC=COLOR_PEOPLE)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=COLOR_PEOPLE, colorT=(255, 255, 255))\n",
    "                elif obj_class in ['bus', 'truck']:\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=COLOR_BIG_VEHICLES, colorC=COLOR_BIG_VEHICLES)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=COLOR_BIG_VEHICLES, colorT=(255, 255, 255))\n",
    "                elif obj_class in ['bicycle', 'motorbike']:\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=COLOR_SMALL_VEHICLES, colorC=COLOR_SMALL_VEHICLES)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=COLOR_SMALL_VEHICLES, colorT=(255, 255, 255))\n",
    "\n",
    "            if ENABLE_TRAFFIC_LIGHTS:\n",
    "                if obj_class == 'green-light':\n",
    "                    detected_green = True\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=TRAFFIC_LIGHT_GREEN, colorC=TRAFFIC_LIGHT_GREEN)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=TRAFFIC_LIGHT_GREEN, colorT=(255, 255, 255))\n",
    "                elif obj_class == 'red-light':\n",
    "                    detected_red = True\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=TRAFFIC_LIGHT_RED, colorC=TRAFFIC_LIGHT_RED)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=TRAFFIC_LIGHT_RED, colorT=(255, 255, 255))\n",
    "                elif obj_class == 'yellow-light':\n",
    "                    cvzone.cornerRect(det_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=TRAFFIC_LIGHT_YELLOW, colorC=TRAFFIC_LIGHT_YELLOW)\n",
    "                    cvzone.putTextRect(det_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=TRAFFIC_LIGHT_YELLOW, colorT=(255, 255, 255))\n",
    "\n",
    "        if SHOW_LIGHTS_BANNER:\n",
    "            frame_height, frame_width, _ = det_frame.shape\n",
    "\n",
    "            if detected_green:\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(\"GREEN LIGHT\", cv2.FONT_HERSHEY_SIMPLEX, 1.2, 2)\n",
    "                padding = 10\n",
    "                bg_rect_y1 = frame_height - text_height - baseline - (2 * padding)\n",
    "                bg_rect_y2 = frame_height - padding\n",
    "                bg_rect_x1 = (frame_width - text_width) // 2 - padding\n",
    "                bg_rect_x2 = bg_rect_x1 + text_width + (2 * padding)\n",
    "\n",
    "                cv2.rectangle(det_frame, (bg_rect_x1, bg_rect_y1), (bg_rect_x2, bg_rect_y2), (0, 80, 0), cv2.FILLED)\n",
    "\n",
    "                text_x = (frame_width - text_width) // 2\n",
    "                text_y = frame_height - baseline - padding - (padding//2)\n",
    "                cv2.putText(det_frame, \"GREEN LIGHT\", (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            elif detected_red:\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(\"RED LIGHT\", cv2.FONT_HERSHEY_SIMPLEX, 1.2, 2)\n",
    "                padding = 10\n",
    "                bg_rect_y1 = frame_height - text_height - baseline - (2 * padding)\n",
    "                bg_rect_y2 = frame_height - padding\n",
    "                bg_rect_x1 = (frame_width - text_width) // 2 - padding\n",
    "                bg_rect_x2 = bg_rect_x1 + text_width + (2 * padding)\n",
    "\n",
    "                cv2.rectangle(det_frame, (bg_rect_x1, bg_rect_y1), (bg_rect_x2, bg_rect_y2), rgb(80, 0, 0), cv2.FILLED)\n",
    "\n",
    "                text_x = (frame_width - text_width) // 2\n",
    "                text_y = frame_height - baseline - padding - (padding//2)\n",
    "                cv2.putText(det_frame, \"RED LIGHT\", (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, rgb(255, 0, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "    if segmentation_results:\n",
    "        s = segmentation_results[0]\n",
    "\n",
    "        if s.masks is not None:\n",
    "            masks_data = s.masks.data\n",
    "            class_ids = s.boxes.cls.cpu().numpy()\n",
    "\n",
    "            if masks_data.shape[0] > 0 and len(class_ids) == masks_data.shape[0]:\n",
    "\n",
    "                for i in range(masks_data.shape[0]):\n",
    "                    mask = masks_data[i]\n",
    "                    cls_id = int(class_ids[i])\n",
    "                    obj_class = CLASS_NAMES_LANES[cls_id]\n",
    "\n",
    "                    resized_mask = torch.nn.functional.interpolate(\n",
    "                        mask.unsqueeze(0).unsqueeze(0),\n",
    "                        size=(frame_height, frame_width), \n",
    "                        mode='bilinear',\n",
    "                        align_corners=False\n",
    "                    ).squeeze()\n",
    "\n",
    "                    binary_mask = (resized_mask > CONFIDENCE_THRESHOLD_SEGMENTATION).float()\n",
    "\n",
    "                    # --- Create Colored Overlay ---\n",
    "                    binary_mask_cpu = binary_mask.cpu().numpy().astype(np.uint8)\n",
    "                    bool_mask_cpu = binary_mask_cpu.astype(bool)\n",
    "\n",
    "                    if ENABLE_LANES and obj_class == 'lane':\n",
    "                        segmentation_overlay[bool_mask_cpu] = COLOR_LANES\n",
    "                    elif ENABLE_ROADS and obj_class == 'road':\n",
    "                        segmentation_overlay[bool_mask_cpu] = COLOR_ROADS\n",
    "\n",
    "                # --- Blend the Overlay with the Frame ---\n",
    "                seg_frame = cv2.addWeighted(segmentation_overlay, OVERLAY_ALPHA, seg_frame, 1 - OVERLAY_ALPHA, 0)\n",
    "\n",
    "    # --- Display ---\n",
    "    cv2.imshow(\"AutoDrive Detection\", det_frame)\n",
    "    cv2.imshow(\"AutoDrive Segmentation\", seg_frame)\n",
    "\n",
    "    # --- Exit Condition ---\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
