{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a361ff9d",
   "metadata": {},
   "source": [
    "## Install and Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b404eb9",
   "metadata": {},
   "source": [
    "**Use CUDA 12.4 with these torch versions!!!**\n",
    "\n",
    "- [Download CUDA 12.4](https://developer.nvidia.com/cuda-12-4-0-download-archive?target_os=Windows&target_arch=x86_64&target_version=11&target_type=exe_local)\n",
    "- [Download cuDNN 8.9.7](https://developer.nvidia.com/rdp/cudnn-archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44560faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install Packages ---\n",
    "#%pip install ultralytics\n",
    "#%pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "#%pip install opencv-python\n",
    "#%pip install cvzone\n",
    "#%pip install numpy\n",
    "\n",
    "# --- Import Libraries ---\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import cvzone\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439f8948",
   "metadata": {},
   "source": [
    "## Preparation and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245ae0be",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ef6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Class Names and RGB Function ---\n",
    "\n",
    "CLASS_NAMES_BASE = [\"pedestrian\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "                    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "                    \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "                    \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "                    \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "                    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "                    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\",\n",
    "                    \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "                    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "                    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\",\n",
    "                    \"toothbrush\"]\n",
    "\n",
    "CLASS_NAMES_TRAFFIC = [\"green-lights\", \"red-lights\", \"yellow-lights\"]\n",
    "\n",
    "CLASS_NAMES_LANES = ['lane', 'road']\n",
    "\n",
    "def to_RGB(r, g, b):\n",
    "    return (b, g, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905738eb",
   "metadata": {},
   "source": [
    "### Configuration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80e6dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration---\n",
    "\n",
    "# --- Source Settings ---\n",
    "VIDEO_SOURCE = \"data/test-videos/test-real-h.mp4\"                  # Horizontal test video from iPhone camera\n",
    "#VIDEO_SOURCE = \"data/test-videos/test-real-v.mp4\"                  # Vertical test video from iPhone camera\n",
    "\n",
    "#VIDEO_SOURCE = \"data/test-videos/test-cars.mp4\"                    # Video for testing cars\n",
    "#VIDEO_SOURCE = \"data/test-videos/test-lights.mp4\"                  # Video for testing traffic lights\n",
    "#VIDEO_SOURCE = \"data/test-videos/test-lines.mp4\"                    # Video for testing lanes and roads   \n",
    "#VIDEO_SOURCE = \"data/test-videos/test-universal.mp4\"               # Video for testing everything\n",
    "\n",
    "#VIDEO_SOURCE = 0                                                   # Webcam for testing real-time\n",
    "\n",
    "\n",
    "# --- Model Settings ---\n",
    "MODEL_PEOPLE_CARS_PATH = \"trained-models/yolo11n.pt\"                  # People and Vehicles detection model   [yolo11l / yolo11n] \n",
    "MODEL_TRAFFIC_LIGHTS_PATH = \"trained-models/v1/lights-nano.pt\"     # Traffic lights detection model        [yoloTLDl / yoloTLDn]\n",
    "MODEL_LANE_SEGMENTATION_PATH = \"trained-models/v1/lane-nano.pt\"    # Lane segmentation model               [yoloLSl / yoloLSn]\n",
    "\n",
    "# --- Visualization Settings ---\n",
    "COLOR_PEOPLE_CARS = to_RGB(130, 0, 255)                           # People and Vehicles: Purple\n",
    "\n",
    "GREEN_TRAFFIC_LIGHT = to_RGB(0, 255, 0)                           # Green traffic light: Green\n",
    "RED_TRAFFIC_LIGHT = to_RGB(255, 0, 0)                             # Red traffic light: Red\n",
    "YELLOW_TRAFFIC_LIGHT = to_RGB(255, 255, 0)                        # Yellow traffic light: Yellow\n",
    "\n",
    "COLOR_LANES = to_RGB(255, 0, 0)                                   # Lanes: Orange\n",
    "COLOR_ROADS = to_RGB(255, 255, 255)                               # Roads: Green\n",
    "\n",
    "# --- Threshold Settings ---\n",
    "CONFIDENCE_THRESHOLD_DETECTION = 0.5                                # Vehicles and Pedestrians detection confidence\n",
    "CONFIDENCE_THRESHOLD_DETECTION_LIGHTS = 0.35                        # Lights detection confidence\n",
    "\n",
    "CONFIDENCE_THRESHOLD_SEGMENTATION = 0.75                            # Lane and Road segmentation confidence\n",
    "OVERLAY_ALPHA = 0.25                                                # Lane and Road mask transparency\n",
    "\n",
    "# --- Detection Settings ---\n",
    "ENABLE_PEOPLE_CARS_DETECTION = True                                # Enable/Disable detection of people and vehicles\n",
    "ENABLE_TRAFFIC_LIGHTS_DETECTION = True                             # Enable/Disable detection of traffic lights\n",
    "ENABLE_LANES = True                                                # Enable/Disable lane segmentation\n",
    "ENABLE_ROADS = False                                                # Enable/Disable road segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125538db",
   "metadata": {},
   "source": [
    "## Model and Source Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c70ef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda [NVIDIA GeForce GTX 1660 SUPER]\n",
      "Models loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Models ---\n",
    "\n",
    "# --- Check Device ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device} [{torch.cuda.get_device_name(0)}]\")\n",
    "\n",
    "# --- Load Models ---\n",
    "model_people_cars = YOLO(MODEL_PEOPLE_CARS_PATH)\n",
    "model_people_cars.to(device)\n",
    "\n",
    "model_traffic_lights = YOLO(MODEL_TRAFFIC_LIGHTS_PATH)\n",
    "model_traffic_lights.to(device)\n",
    "\n",
    "model_lane_segmentation = YOLO(MODEL_LANE_SEGMENTATION_PATH)\n",
    "model_lane_segmentation.to(device)\n",
    "print(\"Models loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccfb33c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening video source: data/test-videos/test-real-h.mp4\n",
      "Video resolution: 944x544\n"
     ]
    }
   ],
   "source": [
    "# --- Video Capture ---\n",
    "print(f\"Opening video source: {\"Camera\" if VIDEO_SOURCE == 0 else VIDEO_SOURCE}\")\n",
    "cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video source\")\n",
    "    exit()\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(f\"Video resolution: {frame_width}x{frame_height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4b6d7a",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e5f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\n",
    "    # Read a frame from the video sourceQ\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video stream or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # --- Inference ---\n",
    "    results_people_cars = model_people_cars.predict(frame, device=device, verbose=False, conf=CONFIDENCE_THRESHOLD_DETECTION)\n",
    "    results_traffic_lights = model_traffic_lights.predict(frame, device=device, verbose=False, conf=CONFIDENCE_THRESHOLD_DETECTION_LIGHTS)\n",
    "    results_lanes = model_lane_segmentation.predict(frame, device=device, verbose=False, conf=CONFIDENCE_THRESHOLD_SEGMENTATION)\n",
    "\n",
    "    processed_frame = frame.copy()\n",
    "    segmentation_overlay = np.zeros_like(processed_frame, dtype=np.uint8)\n",
    "\n",
    "\n",
    "    # --- Model 1: Process Detections for Pedestrians and Vehicles ---\n",
    "    \n",
    "    if ENABLE_PEOPLE_CARS_DETECTION and results_people_cars:\n",
    "        r = results_people_cars[0]\n",
    "        boxes = r.boxes.cpu().numpy()\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            conf = box.conf[0]\n",
    "            cls_id = int(box.cls[0])\n",
    "\n",
    "            obj_class = CLASS_NAMES_BASE[cls_id]\n",
    "\n",
    "            if obj_class in [\"pedestrian\", \"car\", \"truck\", \"bus\", \"motorbike\", \"train\"]:\n",
    "                label = f\"{obj_class}: {conf:.2f}\"\n",
    "                cvzone.cornerRect(processed_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=COLOR_PEOPLE_CARS, colorC=COLOR_PEOPLE_CARS)\n",
    "                cvzone.putTextRect(processed_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=COLOR_PEOPLE_CARS, colorT=(255, 255, 255))\n",
    "\n",
    "\n",
    "    # --- Model 2: Process Detections for Traffic Lights---\n",
    "    if ENABLE_TRAFFIC_LIGHTS_DETECTION and results_traffic_lights:\n",
    "        detected_green = False\n",
    "        detected_red = False\n",
    "\n",
    "        r = results_traffic_lights[0]\n",
    "        boxes = r.boxes.cpu().numpy()\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            conf = box.conf[0]\n",
    "            cls_id = int(box.cls[0])\n",
    "\n",
    "            obj_class = CLASS_NAMES_TRAFFIC[cls_id]\n",
    "            label = f\"{obj_class}: {conf:.2f}\"\n",
    "            if obj_class == CLASS_NAMES_TRAFFIC[0]:\n",
    "                detected_green = True\n",
    "                cvzone.cornerRect(processed_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=GREEN_TRAFFIC_LIGHT, colorC=GREEN_TRAFFIC_LIGHT)\n",
    "                cvzone.putTextRect(processed_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=GREEN_TRAFFIC_LIGHT, colorT=(0, 0, 0))\n",
    "            elif obj_class == CLASS_NAMES_TRAFFIC[1]:\n",
    "                detected_red = True\n",
    "                cvzone.cornerRect(processed_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=RED_TRAFFIC_LIGHT, colorC=RED_TRAFFIC_LIGHT)\n",
    "                cvzone.putTextRect(processed_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=RED_TRAFFIC_LIGHT, colorT=(0, 0, 0))\n",
    "            elif obj_class == CLASS_NAMES_TRAFFIC[2]:\n",
    "                cvzone.cornerRect(processed_frame, (x1, y1, w, h), l=9, t=2, rt=2, colorR=YELLOW_TRAFFIC_LIGHT, colorC=YELLOW_TRAFFIC_LIGHT)\n",
    "                cvzone.putTextRect(processed_frame, label, (max(0, x1), max(35, y1 - 10)), scale=0.6, thickness=1, offset=3, colorR=YELLOW_TRAFFIC_LIGHT, colorT=(0, 0, 0))\n",
    "        \n",
    "        if detected_green:\n",
    "            frame_height, frame_width, _ = processed_frame.shape\n",
    "\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(\"GREEN LIGHT\", cv2.FONT_HERSHEY_SIMPLEX, 1.2, 2)\n",
    "\n",
    "            padding = 10\n",
    "            bg_rect_y1 = frame_height - text_height - baseline - (2 * padding)\n",
    "            bg_rect_y2 = frame_height - padding\n",
    "            bg_rect_x1 = (frame_width - text_width) // 2 - padding\n",
    "            bg_rect_x2 = bg_rect_x1 + text_width + (2 * padding)\n",
    "\n",
    "            cv2.rectangle(processed_frame, (bg_rect_x1, bg_rect_y1), (bg_rect_x2, bg_rect_y2), (0, 80, 0), cv2.FILLED)\n",
    "\n",
    "            text_x = (frame_width - text_width) // 2\n",
    "            text_y = frame_height - baseline - padding - (padding//2)\n",
    "\n",
    "            cv2.putText(processed_frame, \"GREEN LIGHT\", (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        elif detected_red:\n",
    "            frame_height, frame_width, _ = processed_frame.shape\n",
    "\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(\"RED LIGHT\", cv2.FONT_HERSHEY_SIMPLEX, 1.2, 2)\n",
    "\n",
    "            padding = 10\n",
    "            bg_rect_y1 = frame_height - text_height - baseline - (2 * padding)\n",
    "            bg_rect_y2 = frame_height - padding\n",
    "            bg_rect_x1 = (frame_width - text_width) // 2 - padding\n",
    "            bg_rect_x2 = bg_rect_x1 + text_width + (2 * padding)\n",
    "\n",
    "            cv2.rectangle(processed_frame, (bg_rect_x1, bg_rect_y1), (bg_rect_x2, bg_rect_y2), to_RGB(80, 0, 0), cv2.FILLED)\n",
    "\n",
    "            text_x = (frame_width - text_width) // 2\n",
    "            text_y = frame_height - baseline - padding - (padding//2)\n",
    "\n",
    "            cv2.putText(processed_frame, \"RED LIGHT\", (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, to_RGB(255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # --- Model 3: Process Segmentation for Lanes ---\n",
    "    if results_lanes:\n",
    "        r = results_lanes[0]\n",
    "\n",
    "        if r.masks is not None:\n",
    "            masks_data = r.masks.data\n",
    "            class_ids = r.boxes.cls.cpu().numpy()\n",
    "\n",
    "            if masks_data.shape[0] > 0 and len(class_ids) == masks_data.shape[0]:\n",
    "\n",
    "                for i in range(masks_data.shape[0]):\n",
    "                    mask = masks_data[i]\n",
    "                    cls_id = int(class_ids[i])\n",
    "                    obj_class = CLASS_NAMES_LANES[cls_id]\n",
    "\n",
    "                    resized_mask = torch.nn.functional.interpolate(\n",
    "                        mask.unsqueeze(0).unsqueeze(0),\n",
    "                        size=(frame_height, frame_width), \n",
    "                        mode='bilinear',\n",
    "                        align_corners=False\n",
    "                    ).squeeze()\n",
    "\n",
    "                    binary_mask = (resized_mask > CONFIDENCE_THRESHOLD_SEGMENTATION).float()\n",
    "\n",
    "                    # --- Create Colored Overlay ---\n",
    "                    binary_mask_cpu = binary_mask.cpu().numpy().astype(np.uint8)\n",
    "                    bool_mask_cpu = binary_mask_cpu.astype(bool)\n",
    "\n",
    "                    if ENABLE_LANES and obj_class == 'lane':\n",
    "                        segmentation_overlay[bool_mask_cpu] = COLOR_LANES\n",
    "                    elif ENABLE_ROADS and obj_class == 'road':\n",
    "                        segmentation_overlay[bool_mask_cpu] = COLOR_ROADS\n",
    "\n",
    "                # --- Blend the Overlay with the Frame ---\n",
    "                processed_frame = cv2.addWeighted(segmentation_overlay, OVERLAY_ALPHA, processed_frame, 1 - OVERLAY_ALPHA, 0)\n",
    "\n",
    "    # --- Display ---\n",
    "    cv2.imshow(\"AutoDrive Output\", processed_frame)\n",
    "\n",
    "    # --- Exit Condition ---\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
