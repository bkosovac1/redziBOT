{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a361ff9d",
   "metadata": {},
   "source": [
    "# Imports Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44560faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.109-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting numpy<=2.1.1,>=1.23.0 (from ultralytics)\n",
      "  Using cached numpy-2.1.1-cp313-cp313-win_amd64.whl.metadata (59 kB)\n",
      "Collecting matplotlib>=3.3.0 (from ultralytics)\n",
      "  Using cached matplotlib-3.10.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting pillow>=7.1.2 (from ultralytics)\n",
      "  Using cached pillow-11.2.1-cp313-cp313-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests>=2.23.0 (from ultralytics)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting scipy>=1.4.1 (from ultralytics)\n",
      "  Using cached scipy-1.15.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Using cached torch-2.6.0-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Using cached torchvision-0.21.0-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pandas>=1.1.4 (from ultralytics)\n",
      "  Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached contourpy-1.3.2-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached fonttools-4.57.0-cp313-cp313-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached kiwisolver-1.4.8-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.1.4->ultralytics)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.1.4->ultralytics)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting filelock (from torch>=1.8.0->ultralytics)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch>=1.8.0->ultralytics)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch>=1.8.0->ultralytics)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch>=1.8.0->ultralytics)\n",
      "  Using cached setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.8.0->ultralytics)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.8.0->ultralytics)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading ultralytics-8.3.109-py3-none-any.whl (974 kB)\n",
      "   ---------------------------------------- 0.0/974.8 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 786.4/974.8 kB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 974.8/974.8 kB 4.8 MB/s eta 0:00:00\n",
      "Using cached matplotlib-3.10.1-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "Using cached numpy-2.1.1-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "Using cached pillow-11.2.1-cp313-cp313-win_amd64.whl (2.7 MB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached scipy-1.15.2-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached torch-2.6.0-cp313-cp313-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached torchvision-0.21.0-cp313-cp313-win_amd64.whl (1.6 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Using cached contourpy-1.3.2-cp313-cp313-win_amd64.whl (223 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.57.0-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached kiwisolver-1.4.8-cp313-cp313-win_amd64.whl (71 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: pytz, py-cpuinfo, mpmath, urllib3, tzdata, typing-extensions, tqdm, sympy, setuptools, pyyaml, pyparsing, pillow, numpy, networkx, MarkupSafe, kiwisolver, idna, fsspec, fonttools, filelock, cycler, charset-normalizer, certifi, scipy, requests, pandas, opencv-python, jinja2, contourpy, torch, matplotlib, ultralytics-thop, torchvision, seaborn, ultralytics\n",
      "Successfully installed MarkupSafe-3.0.2 certifi-2025.1.31 charset-normalizer-3.4.1 contourpy-1.3.2 cycler-0.12.1 filelock-3.18.0 fonttools-4.57.0 fsspec-2025.3.2 idna-3.10 jinja2-3.1.6 kiwisolver-1.4.8 matplotlib-3.10.1 mpmath-1.3.0 networkx-3.4.2 numpy-2.1.1 opencv-python-4.11.0.86 pandas-2.2.3 pillow-11.2.1 py-cpuinfo-9.0.0 pyparsing-3.2.3 pytz-2025.2 pyyaml-6.0.2 requests-2.32.3 scipy-1.15.2 seaborn-0.13.2 setuptools-78.1.0 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 tqdm-4.67.1 typing-extensions-4.13.2 tzdata-2025.2 ultralytics-8.3.109 ultralytics-thop-2.0.14 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from opencv-python) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting cvzone\n",
      "  Using cached cvzone-1.6.1-py3-none-any.whl\n",
      "Requirement already satisfied: opencv-python in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from cvzone) (4.11.0.86)\n",
      "Requirement already satisfied: numpy in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from cvzone) (2.1.1)\n",
      "Installing collected packages: cvzone\n",
      "Successfully installed cvzone-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: torch in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (0.21.0)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp313-cp313-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from torchvision) (2.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu126/torch-2.6.0%2Bcu126-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\eminh\\desktop\\redzibot\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp313-cp313-win_amd64.whl (4.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu126/torch-2.6.0%2Bcu126-cp313-cp313-win_amd64.whl (2496.1 MB)\n",
      "Installing collected packages: torch, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0\n",
      "    Uninstalling torch-2.6.0:\n",
      "      Successfully uninstalled torch-2.6.0\n",
      "Successfully installed torch-2.6.0+cu126 torchaudio-2.6.0+cu126\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install ultralytics\n",
    "%pip install opencv-python\n",
    "%pip install cvzone\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7514e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Essential Libraries\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b88b740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439f8948",
   "metadata": {},
   "source": [
    "# Vehicle and Pedestrian Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14cb87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = YOLO(\"yolo-weights/yolo11l.pt\")\n",
    "\n",
    "# Class names\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\",\n",
    "              \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\",\n",
    "              \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\",\n",
    "              \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7abefd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load camera as image\n",
    "#cap = cv2.VideoCapture(0)\n",
    "#cap.set(3, 640)\n",
    "#cap.set(4, 360)\n",
    "\n",
    "# Load video as image\n",
    "cap = cv2.VideoCapture(\"data/test-videos/test_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50ffb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nMeta: registered at /dev/null:198 [kernel]\nQuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:503 [backend fallback]\nFunctionalize: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:100 [backend fallback]\nAutogradOther: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMPS: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:91 [backend fallback]\nAutogradXPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:104 [backend fallback]\nAutogradLazy: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradMTIA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMeta: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:95 [backend fallback]\nTracer: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:34 [kernel]\nAutocastXPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:41 [kernel]\nAutocastMPS: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:27 [kernel]\nFuncTorchBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:499 [backend fallback]\nPreDispatch: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:198 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m success, img = cap.read()\n\u001b[32m      4\u001b[39m results = model(img, stream=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mboxes\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Bounding Box\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eminh\\Desktop\\redziBOT\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     40\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eminh\\Desktop\\redziBOT\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:332\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[32m2\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     \u001b[38;5;28mself\u001b[39m.results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim0s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[38;5;28mself\u001b[39m.run_callbacks(\u001b[33m\"\u001b[39m\u001b[33mon_predict_postprocess_end\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    335\u001b[39m \u001b[38;5;66;03m# Visualize, save, write results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eminh\\Desktop\\redziBOT\\.venv\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\predict.py:54\u001b[39m, in \u001b[36mDetectionPredictor.postprocess\u001b[39m\u001b[34m(self, preds, img, orig_imgs, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpostprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds, img, orig_imgs, **kwargs):\n\u001b[32m     34\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[33;03m    Post-process predictions and return a list of Results objects.\u001b[39;00m\n\u001b[32m     36\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m \u001b[33;03m        >>> processed_results = predictor.postprocess(preds, img, orig_imgs)\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     preds = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnon_max_suppression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43miou\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43magnostic_nms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_det\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnc\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[43mend2end\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mend2end\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrotated\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mobb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orig_imgs, \u001b[38;5;28mlist\u001b[39m):  \u001b[38;5;66;03m# input images are a torch.Tensor, not a list\u001b[39;00m\n\u001b[32m     67\u001b[39m         orig_imgs = ops.convert_torch2numpy_batch(orig_imgs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eminh\\Desktop\\redziBOT\\.venv\\Lib\\site-packages\\ultralytics\\utils\\ops.py:312\u001b[39m, in \u001b[36mnon_max_suppression\u001b[39m\u001b[34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated, end2end)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    311\u001b[39m     boxes = x[:, :\u001b[32m4\u001b[39m] + c  \u001b[38;5;66;03m# boxes (offset by class)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     i = \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_thres\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# NMS\u001b[39;00m\n\u001b[32m    313\u001b[39m i = i[:max_det]  \u001b[38;5;66;03m# limit detections\u001b[39;00m\n\u001b[32m    315\u001b[39m \u001b[38;5;66;03m# # Experimental\u001b[39;00m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# merge = False  # use merge-NMS\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;66;03m# if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    324\u001b[39m \u001b[38;5;66;03m#     if redundant:\u001b[39;00m\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m#         i = i[iou.sum(1) > 1]  # require redundancy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eminh\\Desktop\\redziBOT\\.venv\\Lib\\site-packages\\torchvision\\ops\\boxes.py:41\u001b[39m, in \u001b[36mnms\u001b[39m\u001b[34m(boxes, scores, iou_threshold)\u001b[39m\n\u001b[32m     39\u001b[39m     _log_api_usage_once(nms)\n\u001b[32m     40\u001b[39m _assert_has_ops()\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eminh\\Desktop\\redziBOT\\.venv\\Lib\\site-packages\\torch\\_ops.py:1123\u001b[39m, in \u001b[36mOpOverloadPacket.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[32m   1122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mNotImplementedError\u001b[39m: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nMeta: registered at /dev/null:198 [kernel]\nQuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:503 [backend fallback]\nFunctionalize: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:100 [backend fallback]\nAutogradOther: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMPS: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:91 [backend fallback]\nAutogradXPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:104 [backend fallback]\nAutogradLazy: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradMTIA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMeta: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:95 [backend fallback]\nTracer: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:34 [kernel]\nAutocastXPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:41 [kernel]\nAutocastMPS: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:27 [kernel]\nFuncTorchBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:499 [backend fallback]\nPreDispatch: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:198 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "# Drawing on the image\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "\n",
    "            # Bounding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "\n",
    "            # Confidence and Class name box\n",
    "            conf = math.ceil((box.conf[0] * 100)) / 100\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            objclass = classNames[cls]\n",
    "            if objclass == \"person\" or objclass == \"car\" or objclass == \"truck\" or objclass == \"bus\" or objclass == \"bicycle\" or objclass == \"motorbike\" or objclass == \"train\":\n",
    "                cvzone.cornerRect(img, (x1, y1, w, h), l = 8, t = 2)\n",
    "                cvzone.putTextRect(img, f\"{objclass} - {conf}\", (max(0, x1), max(40, y1)), scale=0.6, thickness=1, offset=3)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
